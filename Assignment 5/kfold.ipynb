{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-55ce247fde70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-55ce247fde70>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mtest_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mact_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m           \u001b[1;31m# each segment\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m                     \u001b[0mtest_label\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkmsPredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mact_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0msegment_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m                     \u001b[1;31m# test_label.append(getLable((act_test[i][j, :segment_size*3]), train_centers))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m                 \u001b[0mtest_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-55ce247fde70>\u001b[0m in \u001b[0;36mkmsPredict\u001b[1;34m(model, data)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mkmsPredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetCenter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcluster_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msegment_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, sample_weight)\u001b[0m\n\u001b[0;32m   1074\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cluster_centers_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1076\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1077\u001b[0m         \u001b[0mx_squared_norms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m         return _labels_inertia(X, sample_weight, x_squared_norms,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36m_check_test_data\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m         \u001b[0mexpected_n_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \"\"\"\n\u001b[1;32m--> 492\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "\n",
    "act_num = 14\n",
    "\n",
    "def readData(path):\n",
    "    # activities: data of all activities\n",
    "    # activity: data of each activity\n",
    "    # cur_file: data of each file\n",
    "    # cur_act: data of each line\n",
    "    folders = os.listdir(path)\n",
    "    folders = [x for x in folders if 'MODEL' not in x and 'DS_Store' not in x]\n",
    "\n",
    "    #print(folders)\n",
    "\n",
    "    activities = []\n",
    "    for i in range(act_num):\n",
    "        activity = []\n",
    "        path1 = \"\" + path + \"/\" + folders[i]\n",
    "        files = os.listdir(path1)\n",
    "        random_select = random.sample(range(len(files)), len(files))\n",
    "        for j in random_select:\n",
    "            file = files[j]\n",
    "            cur_file = []\n",
    "            if not os.path.isdir(file):\n",
    "                with open(\"\" + path1 + \"/\" + file, 'r') as f:\n",
    "                    for line in f.readlines():\n",
    "                        cur_act = []\n",
    "                        num = str(line).rstrip(\"\\r\\n\").split(\" \")\n",
    "                        cur_act.append(int(num[0]))\n",
    "                        cur_act.append(int(num[1]))\n",
    "                        cur_act.append(int(num[2]))\n",
    "                        cur_act.append(i)\n",
    "                        cur_act = np.array(cur_act)\n",
    "                        cur_file.append(cur_act)\n",
    "                    cur_file = np.array(cur_file)\n",
    "                    activity.append(cur_file)\n",
    "        activity = np.array(activity)\n",
    "        activities.append(activity)\n",
    "\n",
    "    activities = np.array(activities)\n",
    "    #print(activities)\n",
    "    return folders, activities\n",
    "\n",
    "\n",
    "def splitData(act_data, percent, segment_size):\n",
    "    activities = []\n",
    "    activities_ts = []\n",
    "    train_activities = []\n",
    "    test_activities = []\n",
    "\n",
    "    for i in range(act_num): # each activity\n",
    "        file_num = act_data[i].shape[0]\n",
    "        test_num = math.floor(file_num*(1-percent))                 # number of test files/signals\n",
    "        if(test_num < 1):\n",
    "            test_num = 1\n",
    "        train_num = file_num-test_num                   # number of train files/signals\n",
    "\n",
    "        for j in range(train_num):                      # traverse each train file\n",
    "            train_activity = []\n",
    "            cur_file = act_data[i][j]                   # current file's data\n",
    "            length = cur_file.shape[0]                  # number of samples in current file\n",
    "            segment_num = math.floor(length/segment_size)         # number of segment\n",
    "\n",
    "            for k in range(segment_num):                # build up segment\n",
    "                train_activity.append(cur_file[k*segment_size:(k+1)*segment_size].T.flatten()[:segment_size*3+1])\n",
    "                activities.append(cur_file[k*segment_size:(k+1)*segment_size].T.flatten()[:segment_size*3+1])\n",
    "            train_activity = np.array(train_activity)\n",
    "            train_activities.append(train_activity)\n",
    "\n",
    "        for j in range(train_num, train_num+test_num):                      # traverse each train file\n",
    "            test_activity = []\n",
    "            cur_file = act_data[i][j]                   # current file's data\n",
    "            length = cur_file.shape[0]                  # number of samples in current file\n",
    "            segment_num = math.floor(length/segment_size)         # number of segment\n",
    "\n",
    "            for k in range(segment_num):                # build up segment\n",
    "                test_activity.append(cur_file[k*segment_size:(k+1)*segment_size].T.flatten()[:segment_size*3+1])\n",
    "                activities_ts.append(cur_file[k*segment_size:(k+1)*segment_size].T.flatten()[:segment_size*3+1])\n",
    "            test_activity = np.array(test_activity)\n",
    "            test_activities.append(test_activity)\n",
    "    activities = np.array(activities)\n",
    "    activities_ts = np.array(activities_ts)\n",
    "    train_activities = np.array(train_activities)\n",
    "    test_activities = np.array(test_activities)\n",
    "\n",
    "    return activities, activities_ts, train_activities, test_activities\n",
    "\n",
    "def createTrainHistogram(data, cluster_size, labels, segment_size):\n",
    "    length = data.shape[0]\n",
    "    index = 0\n",
    "\n",
    "    histograms = []\n",
    "    signals = []\n",
    "    for i in range(length):\n",
    "        signal = data[i][0, segment_size*3]\n",
    "        signals.append(signal)\n",
    "        count = np.zeros(cluster_size)\n",
    "        for j in range(data[i].shape[0]):\n",
    "            label = labels[index]\n",
    "            count[label] = count[label] + 1\n",
    "            index += 1\n",
    "        histograms.append(count)\n",
    "    histograms = np.array(histograms)\n",
    "    signals = np.array(signals)\n",
    "\n",
    "    for i in range(length):\n",
    "        total = np.sum(histograms[i])\n",
    "        for j in range(cluster_size):\n",
    "            histograms[i][j] = float(histograms[i][j]) # normalization\n",
    "\n",
    "    return histograms, signals\n",
    "\n",
    "\n",
    "def createTestHistogram(data, cluster_size, labels):\n",
    "    count = np.zeros(cluster_size)\n",
    "    length = data.shape[0]\n",
    "\n",
    "    for i in range(length):\n",
    "        label = labels[i]\n",
    "        count[label] = count[label] + 1\n",
    "\n",
    "    total = np.sum(count)\n",
    "    for i in range(cluster_size):\n",
    "        count[i] = float(count[i])\n",
    "\n",
    "    return count\n",
    "\n",
    "def kms(activities, cluster_size, segment_size):\n",
    "    kmeans = KMeans(n_clusters=cluster_size, random_state=0).fit(activities[:, :segment_size*3])\n",
    "    train_centers = kmeans.cluster_centers_\n",
    "    train_labels = kmeans.labels_\n",
    "    return kmeans, train_labels, train_centers\n",
    "\n",
    "def kmsPredict(model, data):\n",
    "    return model.predict(data)\n",
    "\n",
    "def getCenter(data ,labels, cluster_size, segment_size):\n",
    "    centers = np.array([np.zeros(segment_size*3)]*cluster_size)\n",
    "    label_count = defaultdict(float)\n",
    "    for i in range(data.shape[0]):\n",
    "        label, point = labels[i], data[i]\n",
    "        centers[label] += point\n",
    "        label_count[label] += 1\n",
    "    for i in range(cluster_size):\n",
    "        centers[i] = centers[i] / label_count[i]\n",
    "    return centers\n",
    "\n",
    "def getLable(data, centers):\n",
    "    dist, label = float('inf'), 0\n",
    "    for i in range(centers.shape[0]):\n",
    "        cur_dist = np.linalg.norm(data-centers[i])\n",
    "        if cur_dist < dist:\n",
    "            dist, label = cur_dist ,i \n",
    "    return np.array([label])\n",
    "\n",
    "def draw(histograms, signals, cluster_size, act_name):\n",
    "    for i in range(14):\n",
    "        histogram_sum, count = np.zeros(cluster_size), 0.0\n",
    "        for (histogram, signal) in zip(histograms, signals):\n",
    "            if signal == i:\n",
    "                histogram_sum += histogram\n",
    "                count += 1.0\n",
    "        histogram_sum /= count\n",
    "        plt.bar(range(cluster_size), histogram_sum)\n",
    "        plt.title('Histogram of ' + act_name[i])\n",
    "        plt.savefig('%s.png'%i)\n",
    "        plt.close()\n",
    "\n",
    "def createFolds(data):\n",
    "    folds = []\n",
    "    kf = KFold(n_splits=3, shuffle=True)\n",
    "    for train_indexes, test_indexes in kf.split(data):\n",
    "        fold = np.array([train_indexes, test_indexes])\n",
    "        folds.append(fold)\n",
    "    folds = np.array(folds)\n",
    "    return folds\n",
    "\n",
    "\n",
    "def crossValidateAndTrain(allData, activities, cluster_size, segment_size):\n",
    "    dataFoldsIdx = createFolds(allData)\n",
    "    accuracies = []\n",
    "    cms = []\n",
    "\n",
    "    for fold in dataFoldsIdx:\n",
    "        # Get Data\n",
    "        act_train = allData.take(fold[0], axis=0)\n",
    "        act_train = np.array(act_train)\n",
    "        activities = activities.take(fold[0], axis=0)\n",
    "        activities = np.array(activities)\n",
    "        act_test = allData.take(fold[1], axis=0)\n",
    "        act_test = np.array(act_test)\n",
    "        # Train\n",
    "        model, train_labels, train_centers = kms(activities, cluster_size, segment_size)\n",
    "        #print(model)\n",
    "        train_histogram, train_signal = createTrainHistogram(act_train, cluster_size, train_labels, segment_size)\n",
    "        draw(train_histogram, train_signal, cluster_size, act_name)\n",
    "\n",
    "        test_labels = []\n",
    "        test_samples = act_test.shape[0]\n",
    "        \n",
    "        for i in range(test_samples):                       # each file\n",
    "            test_label = []\n",
    "            for j in range(act_test[i].shape[0]):           # each segment\n",
    "                test_label.append(kmsPredict(model, act_test[i][j, :segment_size*3].reshape(1, -1)))\n",
    "                \n",
    "            test_label = np.array(test_label)\n",
    "            test_labels.append(test_label)\n",
    "        test_labels = np.array(test_labels)\n",
    "\n",
    "        test_histogram = []\n",
    "        for i in range(test_samples):\n",
    "            test_histogram.append(createTestHistogram(act_test[i], cluster_size, test_labels[i]))\n",
    "\n",
    "        rf = RF(max_depth=32, random_state=0, n_estimators=200).fit(train_histogram, train_signal)\n",
    "\n",
    "        accurate = 0\n",
    "        cov_matrix = dict()\n",
    "        for i in range(test_samples):\n",
    "            label = rf.predict(test_histogram[i].reshape(1, -1))[0]\n",
    "            label_ori = act_test[i][0, segment_size*3]\n",
    "            if label_ori not in cov_matrix:\n",
    "                cov_matrix[label_ori] = [0]*14\n",
    "            cov_matrix[label_ori][label] += 1\n",
    "            if int(label) == label_ori:\n",
    "                accurate = accurate + 1\n",
    "        cov_df = pd.DataFrame.from_dict(cov_matrix, orient='index', columns=[str(x) for x in range(14)])\n",
    "        accuracy = (accurate/ len(act_test))*100\n",
    "        print(accuracy)\n",
    "        accuracies.append(accuracy)\n",
    "        cms.append(cov_df)\n",
    "        \n",
    "    return accuracies, cms\n",
    "\n",
    "def main():\n",
    "    act_name, act_data = readData('./HMP_Dataset')\n",
    "    \n",
    "    # Experiments\n",
    "     \n",
    "    print(\"Experiments...\")\n",
    "    trainSize = 2/3\n",
    "\n",
    "    clustersToTry = [4, 8, 16, 20, 25, 30, 40, 50]\n",
    "    segmentSizesToTry = [1, 4, 8, 32, 64]\n",
    "    inertiasBySegment = {}\n",
    "    accPerClusterNumAndSegmentSize = []    \n",
    "    \n",
    "    for segment_size in segmentSizesToTry:\n",
    "        inertias = []    \n",
    "        for cluster_size in clustersToTry:\n",
    "            activities, activities_ts, act_train, act_test = splitData(act_data, trainSize, segment_size)\n",
    "\n",
    "            model, train_labels, train_centers = kms(activities, cluster_size, segment_size)\n",
    "            \n",
    "            inertias.append(model.inertia_)\n",
    "\n",
    "            train_histogram, train_signal = createTrainHistogram(act_train, cluster_size, train_labels, segment_size)\n",
    "            #draw(train_histogram, train_signal, cluster_size, act_name)\n",
    "\n",
    "            test_labels = []\n",
    "            test_samples = act_test.shape[0]\n",
    "            for i in range(test_samples):                       # each file\n",
    "                test_label = []\n",
    "                for j in range(act_test[i].shape[0]):           # each segment\n",
    "                    test_label.append(kmsPredict(model, act_test[i][j, :segment_size*3].reshape(1, -1)))\n",
    "                    # test_label.append(getLable((act_test[i][j, :segment_size*3]), train_centers))\n",
    "                test_label = np.array(test_label)\n",
    "                test_labels.append(test_label)\n",
    "            test_labels = np.array(test_labels)\n",
    "\n",
    "            test_histogram = []\n",
    "            for i in range(test_samples):\n",
    "                test_histogram.append(createTestHistogram(act_test[i], cluster_size, test_labels[i]))\n",
    "\n",
    "            rf = RF(max_depth=32, random_state=0, n_estimators=200).fit(train_histogram, train_signal)\n",
    "            accurate = 0\n",
    "            cov_matrix = dict()\n",
    "            for i in range(test_samples):\n",
    "                label = rf.predict(test_histogram[i].reshape(1, -1))[0]\n",
    "                label_ori = act_test[i][0, segment_size*3]\n",
    "                if label_ori not in cov_matrix:\n",
    "                    cov_matrix[label_ori] = [0]*14\n",
    "                cov_matrix[label_ori][label] += 1\n",
    "                if int(label) == label_ori:\n",
    "                    accurate = accurate + 1\n",
    "            #cov_df = pd.DataFrame.from_dict(cov_matrix, orient='index', columns=[str(x) for x in range(14)])\n",
    "            #cov_df.to_csv('cov.csv',index=False)\n",
    "            acc = (accurate/ len(act_test))*100\n",
    "            print(\" \")\n",
    "            print('Segment: ',segment_size,'   Cluster: ', cluster_size,'    Accuracy: ', acc,'%' )\n",
    "            #print(cov_df)\n",
    "            accPerClusterNumAndSegmentSize.append([cluster_size, segment_size, acc])\n",
    "\n",
    "        inertiasBySegment[segment_size] = inertias\n",
    "\n",
    "    accPerClusterNumAndSegmentSize = np.array(accPerClusterNumAndSegmentSize)\n",
    "    bestAccuracy = accPerClusterNumAndSegmentSize[accPerClusterNumAndSegmentSize[:,2].argsort()][-1]\n",
    "    print(\" \")\n",
    "    print(f'Best accuracy of {bestAccuracy[2]}% with {bestAccuracy[0]} clusters and {bestAccuracy[1]} segments')\n",
    "    print(\" \")\n",
    "    \n",
    "    segment_size= int(bestAccuracy[1])\n",
    "    cluster_size= int(bestAccuracy[0])\n",
    "    matrix_output=True\n",
    "    \n",
    "    tr_activities, ts_activities, act_train, act_test = splitData(act_data, trainSize, segment_size)\n",
    "    \n",
    "    allDataSegmented = np.concatenate((act_train, act_test), axis=0)\n",
    "    allActivities = np.concatenate((tr_activities, ts_activities), axis=0)\n",
    "    #print(allDataSegmented)\n",
    "\n",
    "    results = crossValidateAndTrain(allDataSegmented, allActivities, cluster_size, segment_size )\n",
    "\n",
    "    best_accuracy, best_matrix = results[0][np.argmax(results[0])], results[1][np.argmax(results[0])]\n",
    "    print(f'Best Accuracy of {best_accuracy}%')\n",
    "    print(best_matrix)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
